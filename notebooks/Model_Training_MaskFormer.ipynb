{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q git+https://github.com/huggingface/transformers.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ARk3a0NwgJ4o",
        "outputId": "11259a7e-1a7d-4a42-fb67-4e57adf5a507"
      },
      "id": "ARk3a0NwgJ4o",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m45.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for transformers (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade fsspec"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "akxeTh4AgshR",
        "outputId": "4005c3e2-69fd-4543-8823-50c6ade7010b"
      },
      "id": "akxeTh4AgshR",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (2024.9.0)\n",
            "Collecting fsspec\n",
            "  Using cached fsspec-2024.10.0-py3-none-any.whl.metadata (11 kB)\n",
            "Using cached fsspec-2024.10.0-py3-none-any.whl (179 kB)\n",
            "Installing collected packages: fsspec\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.9.0\n",
            "    Uninstalling fsspec-2024.9.0:\n",
            "      Successfully uninstalled fsspec-2024.9.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datasets 3.2.0 requires fsspec[http]<=2024.9.0,>=2023.1.0, but you have fsspec 2024.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fsspec-2024.10.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q datasets albumentations"
      ],
      "metadata": {
        "id": "ve3frTQ2gNcR"
      },
      "id": "ve3frTQ2gNcR",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install supervision"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "su-k9NybqYgV",
        "outputId": "1ab8dac0-4b2e-41b7-b1f2-de8327e67b1f"
      },
      "id": "su-k9NybqYgV",
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting supervision\n",
            "  Downloading supervision-0.25.1-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: contourpy>=1.0.7 in /usr/local/lib/python3.10/dist-packages (from supervision) (1.3.1)\n",
            "Requirement already satisfied: defusedxml<0.8.0,>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from supervision) (0.7.1)\n",
            "Requirement already satisfied: matplotlib>=3.6.0 in /usr/local/lib/python3.10/dist-packages (from supervision) (3.8.0)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.10/dist-packages (from supervision) (1.26.4)\n",
            "Requirement already satisfied: opencv-python>=4.5.5.64 in /usr/local/lib/python3.10/dist-packages (from supervision) (4.10.0.84)\n",
            "Requirement already satisfied: pillow>=9.4 in /usr/local/lib/python3.10/dist-packages (from supervision) (11.0.0)\n",
            "Requirement already satisfied: pyyaml>=5.3 in /usr/local/lib/python3.10/dist-packages (from supervision) (6.0.2)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from supervision) (2.32.3)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from supervision) (1.13.1)\n",
            "Requirement already satisfied: tqdm>=4.62.3 in /usr/local/lib/python3.10/dist-packages (from supervision) (4.66.6)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (4.55.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (1.4.7)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (24.2)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (3.2.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib>=3.6.0->supervision) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->supervision) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->supervision) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->supervision) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->supervision) (2024.8.30)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib>=3.6.0->supervision) (1.17.0)\n",
            "Downloading supervision-0.25.1-py3-none-any.whl (181 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/181.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.5/181.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: supervision\n",
            "Successfully installed supervision-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "583d5fb9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "583d5fb9",
        "outputId": "e0691505-8c1a-4ef2-f750-ad97c5dbd311"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n",
            "Some weights of MaskFormerForInstanceSegmentation were not initialized from the model checkpoint at facebook/maskformer-swin-tiny-ade and are newly initialized because the shapes did not match:\n",
            "- class_predictor.bias: found shape torch.Size([151]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
            "- class_predictor.weight: found shape torch.Size([151, 256]) in the checkpoint and torch.Size([7, 256]) in the model instantiated\n",
            "- criterion.empty_weight: found shape torch.Size([151]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MaskFormerForInstanceSegmentation(\n",
              "  (model): MaskFormerModel(\n",
              "    (pixel_level_module): MaskFormerPixelLevelModule(\n",
              "      (encoder): MaskFormerSwinBackbone(\n",
              "        (model): MaskFormerSwinModel(\n",
              "          (embeddings): MaskFormerSwinEmbeddings(\n",
              "            (patch_embeddings): MaskFormerSwinPatchEmbeddings(\n",
              "              (projection): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
              "            )\n",
              "            (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "          (encoder): MaskFormerSwinEncoder(\n",
              "            (layers): ModuleList(\n",
              "              (0): MaskFormerSwinStage(\n",
              "                (blocks): ModuleList(\n",
              "                  (0-1): 2 x MaskFormerSwinLayer(\n",
              "                    (layernorm_before): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
              "                    (attention): MaskFormerSwinAttention(\n",
              "                      (self): MaskFormerSwinSelfAttention(\n",
              "                        (query): Linear(in_features=96, out_features=96, bias=True)\n",
              "                        (key): Linear(in_features=96, out_features=96, bias=True)\n",
              "                        (value): Linear(in_features=96, out_features=96, bias=True)\n",
              "                        (dropout): Dropout(p=0.0, inplace=False)\n",
              "                      )\n",
              "                      (output): MaskFormerSwinSelfOutput(\n",
              "                        (dense): Linear(in_features=96, out_features=96, bias=True)\n",
              "                        (dropout): Dropout(p=0.0, inplace=False)\n",
              "                      )\n",
              "                    )\n",
              "                    (drop_path): MaskFormerSwinDropPath(p=0.3)\n",
              "                    (layernorm_after): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
              "                    (intermediate): MaskFormerSwinIntermediate(\n",
              "                      (dense): Linear(in_features=96, out_features=384, bias=True)\n",
              "                      (intermediate_act_fn): GELUActivation()\n",
              "                    )\n",
              "                    (output): MaskFormerSwinOutput(\n",
              "                      (dense): Linear(in_features=384, out_features=96, bias=True)\n",
              "                      (dropout): Dropout(p=0.0, inplace=False)\n",
              "                    )\n",
              "                  )\n",
              "                )\n",
              "                (downsample): MaskFormerSwinPatchMerging(\n",
              "                  (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
              "                  (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "                )\n",
              "              )\n",
              "              (1): MaskFormerSwinStage(\n",
              "                (blocks): ModuleList(\n",
              "                  (0-1): 2 x MaskFormerSwinLayer(\n",
              "                    (layernorm_before): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "                    (attention): MaskFormerSwinAttention(\n",
              "                      (self): MaskFormerSwinSelfAttention(\n",
              "                        (query): Linear(in_features=192, out_features=192, bias=True)\n",
              "                        (key): Linear(in_features=192, out_features=192, bias=True)\n",
              "                        (value): Linear(in_features=192, out_features=192, bias=True)\n",
              "                        (dropout): Dropout(p=0.0, inplace=False)\n",
              "                      )\n",
              "                      (output): MaskFormerSwinSelfOutput(\n",
              "                        (dense): Linear(in_features=192, out_features=192, bias=True)\n",
              "                        (dropout): Dropout(p=0.0, inplace=False)\n",
              "                      )\n",
              "                    )\n",
              "                    (drop_path): MaskFormerSwinDropPath(p=0.3)\n",
              "                    (layernorm_after): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "                    (intermediate): MaskFormerSwinIntermediate(\n",
              "                      (dense): Linear(in_features=192, out_features=768, bias=True)\n",
              "                      (intermediate_act_fn): GELUActivation()\n",
              "                    )\n",
              "                    (output): MaskFormerSwinOutput(\n",
              "                      (dense): Linear(in_features=768, out_features=192, bias=True)\n",
              "                      (dropout): Dropout(p=0.0, inplace=False)\n",
              "                    )\n",
              "                  )\n",
              "                )\n",
              "                (downsample): MaskFormerSwinPatchMerging(\n",
              "                  (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
              "                  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                )\n",
              "              )\n",
              "              (2): MaskFormerSwinStage(\n",
              "                (blocks): ModuleList(\n",
              "                  (0-5): 6 x MaskFormerSwinLayer(\n",
              "                    (layernorm_before): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "                    (attention): MaskFormerSwinAttention(\n",
              "                      (self): MaskFormerSwinSelfAttention(\n",
              "                        (query): Linear(in_features=384, out_features=384, bias=True)\n",
              "                        (key): Linear(in_features=384, out_features=384, bias=True)\n",
              "                        (value): Linear(in_features=384, out_features=384, bias=True)\n",
              "                        (dropout): Dropout(p=0.0, inplace=False)\n",
              "                      )\n",
              "                      (output): MaskFormerSwinSelfOutput(\n",
              "                        (dense): Linear(in_features=384, out_features=384, bias=True)\n",
              "                        (dropout): Dropout(p=0.0, inplace=False)\n",
              "                      )\n",
              "                    )\n",
              "                    (drop_path): MaskFormerSwinDropPath(p=0.3)\n",
              "                    (layernorm_after): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "                    (intermediate): MaskFormerSwinIntermediate(\n",
              "                      (dense): Linear(in_features=384, out_features=1536, bias=True)\n",
              "                      (intermediate_act_fn): GELUActivation()\n",
              "                    )\n",
              "                    (output): MaskFormerSwinOutput(\n",
              "                      (dense): Linear(in_features=1536, out_features=384, bias=True)\n",
              "                      (dropout): Dropout(p=0.0, inplace=False)\n",
              "                    )\n",
              "                  )\n",
              "                )\n",
              "                (downsample): MaskFormerSwinPatchMerging(\n",
              "                  (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
              "                  (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
              "                )\n",
              "              )\n",
              "              (3): MaskFormerSwinStage(\n",
              "                (blocks): ModuleList(\n",
              "                  (0-1): 2 x MaskFormerSwinLayer(\n",
              "                    (layernorm_before): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                    (attention): MaskFormerSwinAttention(\n",
              "                      (self): MaskFormerSwinSelfAttention(\n",
              "                        (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "                        (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "                        (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "                        (dropout): Dropout(p=0.0, inplace=False)\n",
              "                      )\n",
              "                      (output): MaskFormerSwinSelfOutput(\n",
              "                        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "                        (dropout): Dropout(p=0.0, inplace=False)\n",
              "                      )\n",
              "                    )\n",
              "                    (drop_path): MaskFormerSwinDropPath(p=0.3)\n",
              "                    (layernorm_after): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "                    (intermediate): MaskFormerSwinIntermediate(\n",
              "                      (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "                      (intermediate_act_fn): GELUActivation()\n",
              "                    )\n",
              "                    (output): MaskFormerSwinOutput(\n",
              "                      (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "                      (dropout): Dropout(p=0.0, inplace=False)\n",
              "                    )\n",
              "                  )\n",
              "                )\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "          (layernorm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "          (pooler): AdaptiveAvgPool1d(output_size=1)\n",
              "        )\n",
              "        (hidden_states_norms): ModuleList(\n",
              "          (0): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
              "          (1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
              "          (2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
              "          (3): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
              "        )\n",
              "      )\n",
              "      (decoder): MaskFormerPixelDecoder(\n",
              "        (fpn): MaskFormerFPNModel(\n",
              "          (stem): MaskFormerFPNConvLayer(\n",
              "            (0): Conv2d(768, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "            (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "            (2): ReLU(inplace=True)\n",
              "          )\n",
              "          (layers): Sequential(\n",
              "            (0): MaskFormerFPNLayer(\n",
              "              (proj): Sequential(\n",
              "                (0): Conv2d(384, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "              )\n",
              "              (block): MaskFormerFPNConvLayer(\n",
              "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "                (2): ReLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "            (1): MaskFormerFPNLayer(\n",
              "              (proj): Sequential(\n",
              "                (0): Conv2d(192, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "              )\n",
              "              (block): MaskFormerFPNConvLayer(\n",
              "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "                (2): ReLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "            (2): MaskFormerFPNLayer(\n",
              "              (proj): Sequential(\n",
              "                (0): Conv2d(96, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
              "                (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "              )\n",
              "              (block): MaskFormerFPNConvLayer(\n",
              "                (0): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
              "                (1): GroupNorm(32, 256, eps=1e-05, affine=True)\n",
              "                (2): ReLU(inplace=True)\n",
              "              )\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "        (mask_projection): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
              "      )\n",
              "    )\n",
              "    (transformer_module): MaskFormerTransformerModule(\n",
              "      (position_embedder): MaskFormerSinePositionEmbedding()\n",
              "      (queries_embedder): Embedding(100, 256)\n",
              "      (input_projection): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1))\n",
              "      (decoder): DetrDecoder(\n",
              "        (layers): ModuleList(\n",
              "          (0-5): 6 x DetrDecoderLayer(\n",
              "            (self_attn): DetrAttention(\n",
              "              (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            )\n",
              "            (activation_fn): ReLU()\n",
              "            (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "            (encoder_attn): DetrAttention(\n",
              "              (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "              (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
              "            )\n",
              "            (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "            (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
              "            (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
              "            (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "          )\n",
              "        )\n",
              "        (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (class_predictor): Linear(in_features=256, out_features=7, bias=True)\n",
              "  (mask_embedder): MaskformerMLPPredictionHead(\n",
              "    (0): PredictionBlock(\n",
              "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (1): ReLU()\n",
              "    )\n",
              "    (1): PredictionBlock(\n",
              "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (1): ReLU()\n",
              "    )\n",
              "    (2): PredictionBlock(\n",
              "      (0): Linear(in_features=256, out_features=256, bias=True)\n",
              "      (1): Identity()\n",
              "    )\n",
              "  )\n",
              "  (matcher): Matcher MaskFormerHungarianMatcher\n",
              "      cost_class: 1.0\n",
              "      cost_mask: 20.0\n",
              "      cost_dice: 1.0\n",
              "  (criterion): MaskFormerLoss(\n",
              "    (matcher): Matcher MaskFormerHungarianMatcher\n",
              "        cost_class: 1.0\n",
              "        cost_mask: 20.0\n",
              "        cost_dice: 1.0\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "from transformers import MaskFormerForInstanceSegmentation\n",
        "\n",
        "# Load MaskFormer model for semantic segmentation\n",
        "model = MaskFormerForInstanceSegmentation.from_pretrained(\n",
        "    \"facebook/maskformer-swin-tiny-ade\",\n",
        "    num_labels=6,  # Number of labels for the dataset\n",
        "    ignore_mismatched_sizes=True\n",
        ")\n",
        "model.to(\"cuda\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import torch\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from PIL import Image\n",
        "from transformers import MaskFormerImageProcessor\n",
        "\n",
        "\n",
        "from torch.utils.tensorboard import SummaryWriter\n",
        "from torch.utils.data import DataLoader, Dataset"
      ],
      "metadata": {
        "id": "kzfm3QodiUct"
      },
      "id": "kzfm3QodiUct",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "import torch.nn.functional as F\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "class SemanticSegmentationDataset(Dataset):\n",
        "    \"\"\"Image (semantic) segmentation dataset resized to 100x100 resolution.\"\"\"\n",
        "\n",
        "    def __init__(self, image_processor, txt_file, img_dir, masks_dir, target_size=(100, 100)):\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            image_processor: The MaskFormer image processor.\n",
        "            txt_file (str): Path to the .txt file containing filenames.\n",
        "            img_dir (str): Base directory containing the images.\n",
        "            masks_dir (str): Base directory containing the masks.\n",
        "            target_size (tuple): Target resolution for images and masks.\n",
        "        \"\"\"\n",
        "        self.image_processor = image_processor\n",
        "        self.target_size = target_size  # Fixed resolution\n",
        "\n",
        "        # Load filenames from txt file\n",
        "        with open(txt_file, \"r\") as f:\n",
        "            self.filenames = [line.strip() for line in f.readlines()]\n",
        "\n",
        "        # Directories for images and masks\n",
        "        self.img_dir = img_dir\n",
        "        self.masks_dir = masks_dir\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.filenames)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        # Dynamically construct paths\n",
        "        filename = self.filenames[idx]\n",
        "        image_path = os.path.join(self.img_dir, filename)\n",
        "        mask_path = os.path.join(self.masks_dir, filename.replace(\".jpg\", \".npy\"))\n",
        "\n",
        "        # Load image and mask\n",
        "        image = Image.open(image_path).convert(\"RGB\")\n",
        "        mask = np.load(mask_path)\n",
        "\n",
        "        # Resize image\n",
        "        image_resized = image.resize(self.target_size, Image.BILINEAR)\n",
        "\n",
        "        # Resize mask\n",
        "        mask_resized = F.interpolate(\n",
        "            torch.tensor(mask, dtype=torch.float32).unsqueeze(0).unsqueeze(0),\n",
        "            size=self.target_size,\n",
        "            mode=\"nearest\"\n",
        "        ).squeeze(0).squeeze(0).long()\n",
        "\n",
        "        # Process the resized image\n",
        "        encoded_inputs = self.image_processor(\n",
        "            images=image_resized,\n",
        "            return_tensors=\"pt\",\n",
        "            do_resize=False  # Prevent additional resizing\n",
        "        )\n",
        "\n",
        "        return {\n",
        "            \"pixel_values\": encoded_inputs[\"pixel_values\"].squeeze(0),  # Remove batch dimension\n",
        "            \"labels\": mask_resized\n",
        "        }"
      ],
      "metadata": {
        "id": "K3tCswFhiP9v"
      },
      "id": "K3tCswFhiP9v",
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FttVZplemZ9m",
        "outputId": "a2b615d8-b3f4-4e9f-aec2-ce25e467db83"
      },
      "id": "FttVZplemZ9m",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "annotations_file ='/content/drive/My Drive/data/annotations.json'\n",
        "with open(annotations_file, 'r') as f:\n",
        "    annotations = json.load(f)\n",
        "labels = []\n",
        "for annotation in annotations:\n",
        "    for shape in annotation['shapes']:\n",
        "        labels.append(shape['label'])\n",
        "\n",
        "labels = list(set(labels))\n",
        "id_to_label = dict( zip(labels, list(range(1, len(labels) + 1))))"
      ],
      "metadata": {
        "id": "Qjzj65nkpxCx"
      },
      "id": "Qjzj65nkpxCx",
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "masks"
      ],
      "metadata": {
        "id": "eKfR9LFdtwhv"
      },
      "id": "eKfR9LFdtwhv"
    },
    {
      "cell_type": "code",
      "source": [
        "import supervision as sv\n",
        "from pathlib import Path\n",
        "\n",
        "# Define input and output paths\n",
        "data_dir = Path(\"/content/drive/My Drive/data\")\n",
        "output_dir = Path(\"/content/drive/My Drive/data/masks\")\n",
        "\n",
        "# Ensure the masks directory exists\n",
        "output_dir.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Get list of image files\n",
        "images = sorted(list(data_dir.glob(\"imgs/*.jpg\")))\n",
        "\n",
        "# Assuming you have `annotations` and `id_to_label` variables\n",
        "for idx, image_path in enumerate(images):\n",
        "    mask = np.zeros((2662, 4004), dtype=np.uint8)  # Initialize blank mask\n",
        "\n",
        "    # Extract filename without extension\n",
        "    fname = image_path.stem  # Automatically extracts file stem (name without extension)\n",
        "\n",
        "    for annotation in annotations:\n",
        "        for shape in annotation['shapes']:\n",
        "            if shape['frame'] == idx:\n",
        "                if shape['type'] == 'polygon':\n",
        "                    label = id_to_label[shape['label']]\n",
        "                    points = np.array(shape['points'], dtype=np.float32).reshape((-1, 2))\n",
        "                    polygon_mask = sv.polygon_to_mask(points, (4004, 2662))\n",
        "                    polygon_mask[polygon_mask == 1] = label\n",
        "                    mask = np.maximum(mask, polygon_mask)\n",
        "\n",
        "    # Save the mask to the output directory\n",
        "    save_path = output_dir / f\"{fname}.npy\"\n",
        "    np.save(str(save_path), mask)\n",
        "\n",
        "print(\"Masks successfully saved!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vkq7MAlkqLYb",
        "outputId": "427ec73a-8dc6-4131-896f-729382fa4591"
      },
      "id": "Vkq7MAlkqLYb",
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Masks successfully saved!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "image_processor = MaskFormerImageProcessor(ignore_index=255, reduce_labels=False)\n",
        "\n",
        "# Base directories for images and masks\n",
        "img_dir = '/content/drive/My Drive/data/imgs'   # Directory with images\n",
        "masks_dir = '/content/drive/My Drive/data/masks'  # Directory with masks\n",
        "\n",
        "# Paths to train.txt and test.txt files\n",
        "train_txt = '/content/drive/My Drive/data/train.txt'\n",
        "eval_txt = '/content/drive/My Drive/data/test.txt'\n",
        "\n",
        "# Create train and evaluation datasets\n",
        "train_ds = SemanticSegmentationDataset(\n",
        "    image_processor=image_processor,\n",
        "    txt_file=train_txt,\n",
        "    img_dir=img_dir,\n",
        "    masks_dir=masks_dir,\n",
        "    target_size=(100, 100)  # Resize to 100x100\n",
        ")\n",
        "\n",
        "eval_ds = SemanticSegmentationDataset(\n",
        "    image_processor=image_processor,\n",
        "    txt_file=eval_txt,\n",
        "    img_dir=img_dir,\n",
        "    masks_dir=masks_dir,\n",
        "    target_size=(100, 100)\n",
        ")"
      ],
      "metadata": {
        "id": "FTnS5CgBicBy"
      },
      "id": "FTnS5CgBicBy",
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(train_ds, batch_size=8, shuffle=True)\n",
        "eval_dataloader = DataLoader(eval_ds, batch_size=8, shuffle=True)"
      ],
      "metadata": {
        "id": "vjY52u3vsVjA"
      },
      "id": "vjY52u3vsVjA",
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "id": "7e5cd9ca",
      "metadata": {
        "id": "7e5cd9ca"
      },
      "outputs": [],
      "source": [
        "from torch.optim import AdamW\n",
        "from transformers import get_scheduler\n",
        "\n",
        "# Set up optimizer and learning rate scheduler\n",
        "optimizer = AdamW(\n",
        "    model.parameters(),\n",
        "    lr=2e-5,           # Learning rate for MaskFormer\n",
        "    weight_decay=0.01  # Regularization\n",
        ")\n",
        "\n",
        "# Learning rate scheduler\n",
        "num_training_steps = len(train_dataloader) * 200  # Assuming 200 epochs\n",
        "lr_scheduler = get_scheduler(\n",
        "    name=\"linear\",\n",
        "    optimizer=optimizer,\n",
        "    num_warmup_steps=0,\n",
        "    num_training_steps=num_training_steps\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def custom_collate_fn(batch):\n",
        "    pixel_values = torch.stack([item[\"pixel_values\"] for item in batch])  # Batch pixel values\n",
        "    labels = torch.stack([item[\"labels\"] for item in batch])  # Batch labels (masks)\n",
        "    return {\"pixel_values\": pixel_values, \"labels\": labels}"
      ],
      "metadata": {
        "id": "SEmp9ER3wEh3"
      },
      "id": "SEmp9ER3wEh3",
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader\n",
        "from transformers import MaskFormerImageProcessor\n",
        "\n",
        "# Initialize processor\n",
        "image_processor = MaskFormerImageProcessor(ignore_index=255, reduce_labels=False)\n",
        "\n",
        "# Initialize datasets (train.txt and test.txt)\n",
        "train_dataset = SemanticSegmentationDataset(\n",
        "    image_processor=image_processor,\n",
        "    txt_file=train_txt,\n",
        "    img_dir=img_dir,\n",
        "    masks_dir=masks_dir,\n",
        "    target_size=(100, 100)  # Resize to 100x100\n",
        ")\n",
        "\n",
        "eval_dataset = SemanticSegmentationDataset(\n",
        "    image_processor=image_processor,\n",
        "    txt_file=eval_txt,\n",
        "    img_dir=img_dir,\n",
        "    masks_dir=masks_dir,\n",
        "    target_size=(100, 100)\n",
        ")\n",
        "\n",
        "# DataLoaders\n",
        "train_dataloader = DataLoader(\n",
        "    train_dataset,\n",
        "    batch_size=2,   # Set batch size\n",
        "    shuffle=True,   # Shuffle for training\n",
        ")\n",
        "\n",
        "eval_dataloader = DataLoader(\n",
        "    eval_dataset,\n",
        "    batch_size=2,   # Set batch size\n",
        "    shuffle=False   # No shuffle for evaluation\n",
        ")"
      ],
      "metadata": {
        "id": "CrH2-GDtwI89"
      },
      "id": "CrH2-GDtwI89",
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "batch = next(iter(train_dataloader))\n",
        "print(\"Keys in batch:\", batch.keys())\n",
        "print(\"Pixel Values Shape:\", batch[\"pixel_values\"].shape)  # (batch_size, 3, H, W)\n",
        "print(\"Labels Shape:\", batch[\"labels\"].shape)              # (batch_size, H, W)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyEYLEPFwhU4",
        "outputId": "a09566bf-ef9a-4f01-93ac-b0349070d000"
      },
      "id": "iyEYLEPFwhU4",
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keys in batch: dict_keys(['pixel_values', 'labels'])\n",
            "Pixel Values Shape: torch.Size([2, 3, 100, 100])\n",
            "Labels Shape: torch.Size([2, 100, 100])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install evaluate"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MyRj_st-yRSQ",
        "outputId": "2065dfea-3563-4d20-ae32-ca4596ca5e29"
      },
      "id": "MyRj_st-yRSQ",
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting evaluate\n",
            "  Downloading evaluate-0.4.3-py3-none-any.whl.metadata (9.2 kB)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.2.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.26.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.66.6)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.16)\n",
            "Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.26.5)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (24.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.16.1)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.11.10)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2024.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: async-timeout<6.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n",
            "Downloading evaluate-0.4.3-py3-none-any.whl (84 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: evaluate\n",
            "Successfully installed evaluate-0.4.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate"
      ],
      "metadata": {
        "id": "nAlyXHQVyP0v"
      },
      "id": "nAlyXHQVyP0v",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "78250893",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "09ed323bc9b44bd7b4c3e9c5b2a805f9",
            "fa837d8dac3f4d33a75064aa9ed827d2",
            "f06785a57e724bceb5a961ebf2892df1",
            "5a7b4cd96a7c4b60b63a81a987b090ab",
            "507b875bf6f8484393070bd44c135712",
            "f4281f0ba2bc4b19a221c403099d1970",
            "fafb2d6b93044cfea221e10d82f3e51e",
            "bfee4dc4ed4c41a39484525b41849f04",
            "2613779b7fb3451ebf0e52b1c0f1f85a",
            "1847b7877e2d43e4b9628ee979be64c0",
            "ca896449c58445969e2aefb3a6e735b9"
          ]
        },
        "id": "78250893",
        "outputId": "9b52fde5-2064-434c-b18f-85d444520207"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading builder script:   0%|          | 0.00/12.9k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "09ed323bc9b44bd7b4c3e9c5b2a805f9"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "\n",
        "# Define log directory for TensorBoard\n",
        "log_path = './logs'\n",
        "writer = SummaryWriter(log_path)\n",
        "\n",
        "# Load the \"mean_iou\" metric using the evaluate library\n",
        "metric = evaluate.load(\"mean_iou\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1e2d8c00",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1e2d8c00",
        "outputId": "1b2e902d-2445-48b7-b8b6-9858e8b21948"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Using device: cuda\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of MaskFormerForInstanceSegmentation were not initialized from the model checkpoint at facebook/maskformer-swin-tiny-ade and are newly initialized because the shapes did not match:\n",
            "- class_predictor.bias: found shape torch.Size([151]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
            "- class_predictor.weight: found shape torch.Size([151, 256]) in the checkpoint and torch.Size([7, 256]) in the model instantiated\n",
            "- criterion.empty_weight: found shape torch.Size([151]) in the checkpoint and torch.Size([7]) in the model instantiated\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 0\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Step 0, Loss: 5.830498218536377\n",
            "Step 10, Loss: 6.560971736907959\n",
            "Step 20, Loss: 5.460800647735596\n",
            "Step 30, Loss: 4.733295917510986\n",
            "Epoch 0, Average Loss: 5.262798261642456\n",
            "Epoch 1\n",
            "Step 0, Loss: 4.204943656921387\n",
            "Step 10, Loss: 4.216634750366211\n",
            "Step 20, Loss: 4.302879810333252\n",
            "Step 30, Loss: 4.832705020904541\n",
            "Epoch 1, Average Loss: 4.356055777413505\n",
            "Epoch 2\n",
            "Step 0, Loss: 4.720031261444092\n",
            "Step 10, Loss: 5.50396203994751\n",
            "Step 20, Loss: 5.256143569946289\n",
            "Step 30, Loss: 4.309160232543945\n",
            "Epoch 2, Average Loss: 4.492826727458409\n",
            "Epoch 3\n",
            "Step 0, Loss: 4.471733093261719\n",
            "Step 10, Loss: 3.9888269901275635\n",
            "Step 20, Loss: 3.893688201904297\n",
            "Step 30, Loss: 4.678355693817139\n",
            "Epoch 3, Average Loss: 4.368869045802525\n",
            "Epoch 4\n",
            "Step 0, Loss: 4.423816204071045\n",
            "Step 10, Loss: 5.889927387237549\n",
            "Step 20, Loss: 4.688224792480469\n",
            "Step 30, Loss: 3.8095500469207764\n",
            "Epoch 4, Average Loss: 4.391020052773612\n",
            "Epoch 5\n",
            "Step 0, Loss: 4.164350986480713\n",
            "Step 10, Loss: 4.455660343170166\n",
            "Step 20, Loss: 5.045419692993164\n",
            "Step 30, Loss: 4.222134590148926\n",
            "Epoch 5, Average Loss: 4.487730537142072\n",
            "Epoch 6\n",
            "Step 0, Loss: 4.4962263107299805\n",
            "Step 10, Loss: 4.200295925140381\n",
            "Step 20, Loss: 4.322713851928711\n",
            "Step 30, Loss: 4.406116962432861\n",
            "Epoch 6, Average Loss: 4.332421616145543\n",
            "Epoch 7\n",
            "Step 0, Loss: 4.913772106170654\n",
            "Step 10, Loss: 3.9569878578186035\n",
            "Step 20, Loss: 3.9649863243103027\n",
            "Step 30, Loss: 4.297152996063232\n",
            "Epoch 7, Average Loss: 4.395440993990217\n",
            "Epoch 8\n",
            "Step 0, Loss: 4.393996238708496\n",
            "Step 10, Loss: 3.8604819774627686\n",
            "Step 20, Loss: 4.41895866394043\n",
            "Step 30, Loss: 3.1438562870025635\n",
            "Epoch 8, Average Loss: 4.381249993188041\n",
            "Epoch 9\n",
            "Step 0, Loss: 4.401165962219238\n",
            "Step 10, Loss: 4.024287700653076\n",
            "Step 20, Loss: 4.213284969329834\n",
            "Step 30, Loss: 4.178213119506836\n",
            "Epoch 9, Average Loss: 4.473972306932722\n",
            "Epoch 10\n",
            "Step 0, Loss: 4.3620123863220215\n",
            "Step 10, Loss: 4.472158432006836\n",
            "Step 20, Loss: 5.345096588134766\n",
            "Step 30, Loss: 3.767439126968384\n",
            "Epoch 10, Average Loss: 4.470892020634243\n",
            "Epoch 11\n",
            "Step 0, Loss: 5.845799446105957\n",
            "Step 10, Loss: 3.7881367206573486\n",
            "Step 20, Loss: 4.49073600769043\n",
            "Step 30, Loss: 4.5324883460998535\n",
            "Epoch 11, Average Loss: 4.40387567111424\n",
            "Epoch 12\n",
            "Step 0, Loss: 4.389673233032227\n",
            "Step 10, Loss: 4.134321689605713\n",
            "Step 20, Loss: 4.789342880249023\n",
            "Step 30, Loss: 4.289615631103516\n",
            "Epoch 12, Average Loss: 4.413494573320661\n",
            "Epoch 13\n",
            "Step 0, Loss: 4.337265968322754\n",
            "Step 10, Loss: 4.720921993255615\n",
            "Step 20, Loss: 3.9445719718933105\n",
            "Step 30, Loss: 4.2721357345581055\n",
            "Epoch 13, Average Loss: 4.416030318396432\n",
            "Epoch 14\n",
            "Step 0, Loss: 4.425607204437256\n",
            "Step 10, Loss: 4.654946804046631\n",
            "Step 20, Loss: 4.746532917022705\n",
            "Step 30, Loss: 4.0441389083862305\n",
            "Epoch 14, Average Loss: 4.387912266595023\n",
            "Epoch 15\n",
            "Step 0, Loss: 4.4019389152526855\n",
            "Step 10, Loss: 4.453169345855713\n",
            "Step 20, Loss: 4.39858341217041\n",
            "Step 30, Loss: 4.590524673461914\n",
            "Epoch 15, Average Loss: 4.460270350319998\n",
            "Epoch 16\n",
            "Step 0, Loss: 4.484546661376953\n",
            "Step 10, Loss: 4.414504528045654\n",
            "Step 20, Loss: 4.3670654296875\n",
            "Step 30, Loss: 5.042784214019775\n",
            "Epoch 16, Average Loss: 4.339856556483677\n",
            "Epoch 17\n",
            "Step 0, Loss: 4.893137454986572\n",
            "Step 10, Loss: 4.673424243927002\n",
            "Step 20, Loss: 4.448505878448486\n",
            "Step 30, Loss: 5.627159595489502\n",
            "Epoch 17, Average Loss: 4.502571303503854\n",
            "Epoch 18\n",
            "Step 0, Loss: 3.7735347747802734\n",
            "Step 10, Loss: 4.2409515380859375\n",
            "Step 20, Loss: 3.8832764625549316\n",
            "Step 30, Loss: 4.285818576812744\n",
            "Epoch 18, Average Loss: 4.471913978031703\n",
            "Epoch 19\n",
            "Step 0, Loss: 3.470864772796631\n",
            "Step 10, Loss: 5.365432262420654\n",
            "Step 20, Loss: 4.346869945526123\n",
            "Step 30, Loss: 4.217595100402832\n",
            "Epoch 19, Average Loss: 4.419152859279087\n",
            "Epoch 20\n",
            "Step 0, Loss: 3.9107930660247803\n",
            "Step 10, Loss: 4.7730712890625\n",
            "Step 20, Loss: 4.289994716644287\n",
            "Step 30, Loss: 5.084632396697998\n",
            "Epoch 20, Average Loss: 4.47602823802403\n",
            "Epoch 21\n",
            "Step 0, Loss: 4.257766246795654\n",
            "Step 10, Loss: 4.25131893157959\n",
            "Step 20, Loss: 4.416275501251221\n",
            "Step 30, Loss: 4.290463447570801\n",
            "Epoch 21, Average Loss: 4.485525860105242\n",
            "Epoch 22\n",
            "Step 0, Loss: 4.849853038787842\n",
            "Step 10, Loss: 4.6935133934021\n",
            "Step 20, Loss: 4.436062335968018\n",
            "Step 30, Loss: 3.843601942062378\n",
            "Epoch 22, Average Loss: 4.482694387435913\n",
            "Epoch 23\n",
            "Step 0, Loss: 4.571189880371094\n",
            "Step 10, Loss: 4.095390796661377\n",
            "Step 20, Loss: 4.832799434661865\n",
            "Step 30, Loss: 4.307702541351318\n",
            "Epoch 23, Average Loss: 4.418515702656337\n",
            "Epoch 24\n",
            "Step 0, Loss: 4.360537528991699\n",
            "Step 10, Loss: 4.16239595413208\n",
            "Step 20, Loss: 4.592349052429199\n",
            "Step 30, Loss: 4.346875190734863\n",
            "Epoch 24, Average Loss: 4.387339646475656\n",
            "Epoch 25\n",
            "Step 0, Loss: 4.137112617492676\n",
            "Step 10, Loss: 4.454361915588379\n",
            "Step 20, Loss: 4.254806041717529\n",
            "Step 30, Loss: 4.3362627029418945\n",
            "Epoch 25, Average Loss: 4.434665489196777\n",
            "Epoch 26\n",
            "Step 0, Loss: 4.1961445808410645\n",
            "Step 10, Loss: 3.670603036880493\n",
            "Step 20, Loss: 4.092828750610352\n",
            "Step 30, Loss: 4.3029937744140625\n",
            "Epoch 26, Average Loss: 4.421716506140573\n",
            "Epoch 27\n",
            "Step 0, Loss: 5.165346622467041\n",
            "Step 10, Loss: 4.535524368286133\n",
            "Step 20, Loss: 4.386648178100586\n",
            "Step 30, Loss: 4.081759452819824\n",
            "Epoch 27, Average Loss: 4.538123253413609\n",
            "Epoch 28\n",
            "Step 0, Loss: 4.504645347595215\n",
            "Step 10, Loss: 3.8131093978881836\n",
            "Step 20, Loss: 4.585677146911621\n",
            "Step 30, Loss: 4.3982834815979\n",
            "Epoch 28, Average Loss: 4.618925108228411\n",
            "Epoch 29\n",
            "Step 0, Loss: 4.315547466278076\n",
            "Step 10, Loss: 4.7586750984191895\n",
            "Step 20, Loss: 4.767664909362793\n",
            "Step 30, Loss: 4.370476722717285\n",
            "Epoch 29, Average Loss: 4.408752863747733\n",
            "Epoch 30\n",
            "Step 0, Loss: 4.177130222320557\n",
            "Step 10, Loss: 4.575995922088623\n",
            "Step 20, Loss: 6.131062984466553\n",
            "Step 30, Loss: 3.9747960567474365\n",
            "Epoch 30, Average Loss: 4.470995044708252\n",
            "Epoch 31\n",
            "Step 0, Loss: 3.8427937030792236\n",
            "Step 10, Loss: 4.611527919769287\n",
            "Step 20, Loss: 4.276517868041992\n",
            "Step 30, Loss: 4.165234565734863\n",
            "Epoch 31, Average Loss: 4.356435142244611\n",
            "Epoch 32\n",
            "Step 0, Loss: 5.01010799407959\n",
            "Step 10, Loss: 4.864039897918701\n",
            "Step 20, Loss: 4.1001787185668945\n",
            "Step 30, Loss: 4.353667736053467\n",
            "Epoch 32, Average Loss: 4.44487658909389\n",
            "Epoch 33\n",
            "Step 0, Loss: 4.144340991973877\n",
            "Step 10, Loss: 4.033145904541016\n",
            "Step 20, Loss: 4.496850967407227\n",
            "Step 30, Loss: 4.05636739730835\n",
            "Epoch 33, Average Loss: 4.460699149540493\n",
            "Epoch 34\n",
            "Step 0, Loss: 4.617595195770264\n",
            "Step 10, Loss: 4.164465427398682\n",
            "Step 20, Loss: 3.732851505279541\n",
            "Step 30, Loss: 4.8923211097717285\n",
            "Epoch 34, Average Loss: 4.39509790965489\n",
            "Epoch 35\n",
            "Step 0, Loss: 4.241318225860596\n",
            "Step 10, Loss: 4.0366315841674805\n",
            "Step 20, Loss: 4.44334602355957\n",
            "Step 30, Loss: 5.217963218688965\n",
            "Epoch 35, Average Loss: 4.409666034153529\n",
            "Epoch 36\n",
            "Step 0, Loss: 3.990504741668701\n",
            "Step 10, Loss: 4.735257148742676\n",
            "Step 20, Loss: 5.441301345825195\n",
            "Step 30, Loss: 4.266733646392822\n",
            "Epoch 36, Average Loss: 4.395822068623134\n",
            "Epoch 37\n",
            "Step 0, Loss: 6.058845520019531\n",
            "Step 10, Loss: 4.582696914672852\n",
            "Step 20, Loss: 4.394251346588135\n",
            "Step 30, Loss: 3.587540626525879\n",
            "Epoch 37, Average Loss: 4.469239561898368\n",
            "Epoch 38\n",
            "Step 0, Loss: 4.124383449554443\n",
            "Step 10, Loss: 4.0600905418396\n",
            "Step 20, Loss: 4.388591289520264\n",
            "Step 30, Loss: 4.518176555633545\n",
            "Epoch 38, Average Loss: 4.456139285223824\n",
            "Epoch 39\n",
            "Step 0, Loss: 4.027518272399902\n",
            "Step 10, Loss: 4.422412395477295\n",
            "Step 20, Loss: 4.85877799987793\n",
            "Step 30, Loss: 3.798146963119507\n",
            "Epoch 39, Average Loss: 4.388579368591309\n",
            "Epoch 40\n",
            "Step 0, Loss: 5.772885322570801\n",
            "Step 10, Loss: 4.7347869873046875\n",
            "Step 20, Loss: 4.499847412109375\n",
            "Step 30, Loss: 4.3653564453125\n",
            "Epoch 40, Average Loss: 4.510419395991734\n",
            "Epoch 41\n",
            "Step 0, Loss: 4.008634567260742\n",
            "Step 10, Loss: 4.297554016113281\n",
            "Step 20, Loss: 4.5834455490112305\n",
            "Step 30, Loss: 6.912810802459717\n",
            "Epoch 41, Average Loss: 4.523843901497977\n",
            "Epoch 42\n",
            "Step 0, Loss: 3.8014469146728516\n",
            "Step 10, Loss: 4.20451545715332\n",
            "Step 20, Loss: 4.79860258102417\n",
            "Step 30, Loss: 3.6033167839050293\n",
            "Epoch 42, Average Loss: 4.490913193566459\n",
            "Epoch 43\n",
            "Step 0, Loss: 4.090498447418213\n",
            "Step 10, Loss: 3.9800662994384766\n",
            "Step 20, Loss: 4.1545257568359375\n",
            "Step 30, Loss: 4.160271644592285\n",
            "Epoch 43, Average Loss: 4.4112104892730715\n",
            "Epoch 44\n",
            "Step 0, Loss: 4.109738349914551\n",
            "Step 10, Loss: 3.782351493835449\n",
            "Step 20, Loss: 3.6841840744018555\n",
            "Step 30, Loss: 4.47680139541626\n",
            "Epoch 44, Average Loss: 4.3881628104618615\n",
            "Epoch 45\n",
            "Step 0, Loss: 5.455291271209717\n",
            "Step 10, Loss: 4.902002334594727\n",
            "Step 20, Loss: 3.920154333114624\n",
            "Step 30, Loss: 4.2999653816223145\n",
            "Epoch 45, Average Loss: 4.459670748029437\n",
            "Epoch 46\n",
            "Step 0, Loss: 4.403379440307617\n",
            "Step 10, Loss: 4.292874813079834\n",
            "Step 20, Loss: 5.671200275421143\n",
            "Step 30, Loss: 4.361128330230713\n",
            "Epoch 46, Average Loss: 4.513213532311576\n",
            "Epoch 47\n",
            "Step 0, Loss: 4.423168182373047\n",
            "Step 10, Loss: 4.3531928062438965\n",
            "Step 20, Loss: 4.488411903381348\n",
            "Step 30, Loss: 4.128478527069092\n",
            "Epoch 47, Average Loss: 4.450997958864485\n",
            "Epoch 48\n",
            "Step 0, Loss: 4.376561164855957\n",
            "Step 10, Loss: 4.961483001708984\n",
            "Step 20, Loss: 4.181591033935547\n",
            "Step 30, Loss: 4.8016767501831055\n",
            "Epoch 48, Average Loss: 4.367551558358329\n",
            "Epoch 49\n",
            "Step 0, Loss: 5.11895751953125\n",
            "Step 10, Loss: 4.148619651794434\n",
            "Step 20, Loss: 4.117391586303711\n",
            "Step 30, Loss: 4.437136650085449\n",
            "Epoch 49, Average Loss: 4.453788573401315\n",
            "Epoch 50\n",
            "Step 0, Loss: 4.967470169067383\n",
            "Step 10, Loss: 4.494119644165039\n",
            "Step 20, Loss: 4.315685749053955\n",
            "Step 30, Loss: 4.097548484802246\n",
            "Epoch 50, Average Loss: 4.4316367898668565\n",
            "Epoch 51\n",
            "Step 0, Loss: 4.90245246887207\n",
            "Step 10, Loss: 3.8794054985046387\n",
            "Step 20, Loss: 4.232191562652588\n",
            "Step 30, Loss: 4.405940055847168\n",
            "Epoch 51, Average Loss: 4.391705826350621\n",
            "Epoch 52\n",
            "Step 0, Loss: 4.454854965209961\n",
            "Step 10, Loss: 4.112396717071533\n",
            "Step 20, Loss: 4.394254684448242\n",
            "Step 30, Loss: 4.053750038146973\n",
            "Epoch 52, Average Loss: 4.4759670393807545\n",
            "Epoch 53\n",
            "Step 0, Loss: 7.015081405639648\n",
            "Step 10, Loss: 4.292491436004639\n",
            "Step 20, Loss: 3.7241530418395996\n",
            "Step 30, Loss: 4.91909122467041\n",
            "Epoch 53, Average Loss: 4.47307996068682\n",
            "Epoch 54\n",
            "Step 0, Loss: 5.004176616668701\n",
            "Step 10, Loss: 5.325865745544434\n",
            "Step 20, Loss: 3.7812788486480713\n",
            "Step 30, Loss: 4.008652210235596\n",
            "Epoch 54, Average Loss: 4.5112208570752825\n",
            "Epoch 55\n",
            "Step 0, Loss: 3.8284194469451904\n",
            "Step 10, Loss: 3.6953163146972656\n",
            "Step 20, Loss: 4.5654754638671875\n",
            "Step 30, Loss: 4.400169372558594\n",
            "Epoch 55, Average Loss: 4.312115505763463\n",
            "Epoch 56\n",
            "Step 0, Loss: 4.907650947570801\n",
            "Step 10, Loss: 4.945376873016357\n",
            "Step 20, Loss: 4.128087997436523\n",
            "Step 30, Loss: 3.9921329021453857\n",
            "Epoch 56, Average Loss: 4.488589688709804\n",
            "Epoch 57\n",
            "Step 0, Loss: 4.413769245147705\n",
            "Step 10, Loss: 4.335610389709473\n",
            "Step 20, Loss: 4.580798625946045\n",
            "Step 30, Loss: 3.9241816997528076\n",
            "Epoch 57, Average Loss: 4.395856925419399\n",
            "Epoch 58\n",
            "Step 0, Loss: 4.325500011444092\n",
            "Step 10, Loss: 4.588829517364502\n",
            "Step 20, Loss: 4.26001501083374\n",
            "Step 30, Loss: 4.953400135040283\n",
            "Epoch 58, Average Loss: 4.45520692552839\n",
            "Epoch 59\n",
            "Step 0, Loss: 4.200535297393799\n",
            "Step 10, Loss: 4.456304550170898\n",
            "Step 20, Loss: 4.259403228759766\n",
            "Step 30, Loss: 4.157687187194824\n",
            "Epoch 59, Average Loss: 4.339967244012016\n",
            "Epoch 60\n",
            "Step 0, Loss: 4.272019386291504\n",
            "Step 10, Loss: 4.130112648010254\n",
            "Step 20, Loss: 4.610051155090332\n",
            "Step 30, Loss: 6.268981456756592\n",
            "Epoch 60, Average Loss: 4.40668580872672\n",
            "Epoch 61\n",
            "Step 0, Loss: 4.757591724395752\n",
            "Step 10, Loss: 5.087038040161133\n",
            "Step 20, Loss: 3.871140718460083\n",
            "Step 30, Loss: 5.55272912979126\n",
            "Epoch 61, Average Loss: 4.446603413990566\n",
            "Epoch 62\n",
            "Step 0, Loss: 4.711241245269775\n",
            "Step 10, Loss: 4.608368396759033\n",
            "Step 20, Loss: 3.841702461242676\n",
            "Step 30, Loss: 3.577340602874756\n",
            "Epoch 62, Average Loss: 4.36788386617388\n",
            "Epoch 63\n",
            "Step 0, Loss: 4.538674831390381\n",
            "Step 10, Loss: 4.366842746734619\n",
            "Step 20, Loss: 4.247707843780518\n",
            "Step 30, Loss: 3.7275664806365967\n",
            "Epoch 63, Average Loss: 4.460374764033726\n",
            "Epoch 64\n",
            "Step 0, Loss: 4.216750144958496\n",
            "Step 10, Loss: 4.160745143890381\n",
            "Step 20, Loss: 4.413747787475586\n",
            "Step 30, Loss: 4.16341495513916\n",
            "Epoch 64, Average Loss: 4.395201894215175\n",
            "Epoch 65\n",
            "Step 0, Loss: 4.507597923278809\n",
            "Step 10, Loss: 4.177141189575195\n",
            "Step 20, Loss: 4.218503952026367\n",
            "Step 30, Loss: 3.471457004547119\n",
            "Epoch 65, Average Loss: 4.405032341820853\n",
            "Epoch 66\n",
            "Step 0, Loss: 4.218019485473633\n",
            "Step 10, Loss: 4.812690258026123\n",
            "Step 20, Loss: 4.582702159881592\n",
            "Step 30, Loss: 4.696052551269531\n",
            "Epoch 66, Average Loss: 4.554466990062169\n",
            "Epoch 67\n",
            "Step 0, Loss: 5.042629718780518\n",
            "Step 10, Loss: 4.688867568969727\n",
            "Step 20, Loss: 3.807351589202881\n",
            "Step 30, Loss: 4.537631034851074\n",
            "Epoch 67, Average Loss: 4.405277122770037\n",
            "Epoch 68\n",
            "Step 0, Loss: 4.5690226554870605\n",
            "Step 10, Loss: 4.673611164093018\n",
            "Step 20, Loss: 4.087453842163086\n",
            "Step 30, Loss: 4.207115173339844\n",
            "Epoch 68, Average Loss: 4.3948789460318425\n",
            "Epoch 69\n",
            "Step 0, Loss: 4.014377593994141\n",
            "Step 10, Loss: 4.723985195159912\n",
            "Step 20, Loss: 4.135401725769043\n",
            "Step 30, Loss: 4.2605438232421875\n",
            "Epoch 69, Average Loss: 4.639663301195417\n",
            "Epoch 70\n",
            "Step 0, Loss: 4.205032825469971\n",
            "Step 10, Loss: 4.476162433624268\n",
            "Step 20, Loss: 4.022073268890381\n",
            "Step 30, Loss: 4.317385196685791\n",
            "Epoch 70, Average Loss: 4.428997503008161\n",
            "Epoch 71\n",
            "Step 0, Loss: 5.445526123046875\n",
            "Step 10, Loss: 4.202421188354492\n",
            "Step 20, Loss: 4.93349552154541\n",
            "Step 30, Loss: 4.164245128631592\n",
            "Epoch 71, Average Loss: 4.415411342893328\n",
            "Epoch 72\n",
            "Step 0, Loss: 4.8067803382873535\n",
            "Step 10, Loss: 4.249608516693115\n",
            "Step 20, Loss: 4.517506122589111\n",
            "Step 30, Loss: 4.225230693817139\n",
            "Epoch 72, Average Loss: 4.480382067816598\n",
            "Epoch 73\n",
            "Step 0, Loss: 4.3699951171875\n",
            "Step 10, Loss: 4.951584339141846\n",
            "Step 20, Loss: 3.7616655826568604\n",
            "Step 30, Loss: 4.403432846069336\n",
            "Epoch 73, Average Loss: 4.418016195297241\n",
            "Epoch 74\n",
            "Step 0, Loss: 4.6775007247924805\n",
            "Step 10, Loss: 4.5401692390441895\n",
            "Step 20, Loss: 4.5002055168151855\n",
            "Step 30, Loss: 4.565396785736084\n",
            "Epoch 74, Average Loss: 4.481346729823521\n",
            "Epoch 75\n",
            "Step 0, Loss: 4.033750057220459\n",
            "Step 10, Loss: 4.6139140129089355\n",
            "Step 20, Loss: 4.314813613891602\n",
            "Step 30, Loss: 4.2985639572143555\n",
            "Epoch 75, Average Loss: 4.414157860619682\n",
            "Epoch 76\n",
            "Step 0, Loss: 3.8428938388824463\n",
            "Step 10, Loss: 4.919944763183594\n",
            "Step 20, Loss: 4.274360179901123\n",
            "Step 30, Loss: 4.289842128753662\n",
            "Epoch 76, Average Loss: 4.472192028590611\n",
            "Epoch 77\n",
            "Step 0, Loss: 4.917271137237549\n",
            "Step 10, Loss: 3.5647382736206055\n",
            "Step 20, Loss: 4.468976020812988\n",
            "Step 30, Loss: 4.719089031219482\n",
            "Epoch 77, Average Loss: 4.500449936730521\n",
            "Epoch 78\n",
            "Step 0, Loss: 4.572118759155273\n",
            "Step 10, Loss: 3.981842279434204\n",
            "Step 20, Loss: 4.363779067993164\n",
            "Step 30, Loss: 4.844402313232422\n",
            "Epoch 78, Average Loss: 4.425804056440081\n",
            "Epoch 79\n",
            "Step 0, Loss: 4.478025913238525\n",
            "Step 10, Loss: 4.588751316070557\n",
            "Step 20, Loss: 3.8695335388183594\n",
            "Step 30, Loss: 4.389034748077393\n",
            "Epoch 79, Average Loss: 4.433196142741612\n",
            "Epoch 80\n",
            "Step 0, Loss: 4.36041784286499\n",
            "Step 10, Loss: 4.158210754394531\n",
            "Step 20, Loss: 4.697513103485107\n",
            "Step 30, Loss: 4.5689873695373535\n",
            "Epoch 80, Average Loss: 4.392380775724138\n",
            "Epoch 81\n",
            "Step 0, Loss: 4.6321611404418945\n",
            "Step 10, Loss: 4.650886058807373\n",
            "Step 20, Loss: 4.15104866027832\n",
            "Step 30, Loss: 4.165463924407959\n",
            "Epoch 81, Average Loss: 4.489725623811994\n",
            "Epoch 82\n",
            "Step 0, Loss: 3.9285194873809814\n",
            "Step 10, Loss: 4.395211219787598\n",
            "Step 20, Loss: 4.688612461090088\n",
            "Step 30, Loss: 4.462440013885498\n",
            "Epoch 82, Average Loss: 4.481251866476876\n",
            "Epoch 83\n",
            "Step 0, Loss: 4.708252906799316\n",
            "Step 10, Loss: 4.488734245300293\n",
            "Step 20, Loss: 4.4190826416015625\n",
            "Step 30, Loss: 4.281878471374512\n",
            "Epoch 83, Average Loss: 4.496759128570557\n",
            "Epoch 84\n",
            "Step 0, Loss: 4.015557289123535\n",
            "Step 10, Loss: 5.449451923370361\n",
            "Step 20, Loss: 4.424071311950684\n",
            "Step 30, Loss: 4.164527893066406\n",
            "Epoch 84, Average Loss: 4.440640851429531\n",
            "Epoch 85\n",
            "Step 0, Loss: 3.981795310974121\n",
            "Step 10, Loss: 4.541963577270508\n",
            "Step 20, Loss: 3.696779727935791\n",
            "Step 30, Loss: 4.629009246826172\n",
            "Epoch 85, Average Loss: 4.436351612636021\n",
            "Epoch 86\n",
            "Step 0, Loss: 3.7407546043395996\n",
            "Step 10, Loss: 4.4856181144714355\n",
            "Step 20, Loss: 4.023989677429199\n",
            "Step 30, Loss: 3.626791477203369\n",
            "Epoch 86, Average Loss: 4.34733749798366\n",
            "Epoch 87\n",
            "Step 0, Loss: 4.583591461181641\n",
            "Step 10, Loss: 3.7456655502319336\n",
            "Step 20, Loss: 4.71633768081665\n",
            "Step 30, Loss: 4.273202896118164\n",
            "Epoch 87, Average Loss: 4.42149338722229\n",
            "Epoch 88\n",
            "Step 0, Loss: 4.9763264656066895\n",
            "Step 10, Loss: 4.101461887359619\n",
            "Step 20, Loss: 4.255945682525635\n",
            "Step 30, Loss: 3.8692753314971924\n",
            "Epoch 88, Average Loss: 4.344260515485491\n",
            "Epoch 89\n",
            "Step 0, Loss: 4.9744062423706055\n",
            "Step 10, Loss: 4.284678936004639\n",
            "Step 20, Loss: 5.0355024337768555\n",
            "Step 30, Loss: 4.132231712341309\n",
            "Epoch 89, Average Loss: 4.560294158118111\n",
            "Epoch 90\n",
            "Step 0, Loss: 4.1387481689453125\n",
            "Step 10, Loss: 4.089108467102051\n",
            "Step 20, Loss: 4.384273529052734\n",
            "Step 30, Loss: 3.9615867137908936\n",
            "Epoch 90, Average Loss: 4.377141073771885\n",
            "Epoch 91\n",
            "Step 0, Loss: 4.324719429016113\n",
            "Step 10, Loss: 4.275092601776123\n",
            "Step 20, Loss: 3.744391441345215\n",
            "Step 30, Loss: 3.656593084335327\n",
            "Epoch 91, Average Loss: 4.48372756413051\n",
            "Epoch 92\n",
            "Step 0, Loss: 4.2209672927856445\n",
            "Step 10, Loss: 4.82052755355835\n",
            "Step 20, Loss: 4.161897659301758\n",
            "Step 30, Loss: 4.364211559295654\n",
            "Epoch 92, Average Loss: 4.496273108891079\n",
            "Epoch 93\n",
            "Step 0, Loss: 4.294942378997803\n",
            "Step 10, Loss: 3.9474668502807617\n",
            "Step 20, Loss: 5.220091342926025\n",
            "Step 30, Loss: 4.250015735626221\n",
            "Epoch 93, Average Loss: 4.418126433236258\n",
            "Epoch 94\n",
            "Step 0, Loss: 4.460238933563232\n",
            "Step 10, Loss: 3.987088203430176\n",
            "Step 20, Loss: 4.397830963134766\n",
            "Step 30, Loss: 4.04125452041626\n",
            "Epoch 94, Average Loss: 4.455101149422782\n",
            "Epoch 95\n",
            "Step 0, Loss: 4.235335350036621\n",
            "Step 10, Loss: 5.145615577697754\n",
            "Step 20, Loss: 4.185070037841797\n",
            "Step 30, Loss: 5.515023708343506\n",
            "Epoch 95, Average Loss: 4.407472460610526\n",
            "Epoch 96\n",
            "Step 0, Loss: 4.355775356292725\n",
            "Step 10, Loss: 4.451443195343018\n",
            "Step 20, Loss: 5.812502384185791\n",
            "Step 30, Loss: 4.77997350692749\n",
            "Epoch 96, Average Loss: 4.457228027071271\n",
            "Epoch 97\n",
            "Step 0, Loss: 4.154436111450195\n",
            "Step 10, Loss: 4.339561939239502\n",
            "Step 20, Loss: 4.044413089752197\n",
            "Step 30, Loss: 4.03413724899292\n",
            "Epoch 97, Average Loss: 4.459143713542393\n",
            "Epoch 98\n",
            "Step 0, Loss: 3.664067506790161\n",
            "Step 10, Loss: 4.542960166931152\n",
            "Step 20, Loss: 4.007058620452881\n",
            "Step 30, Loss: 4.330570220947266\n",
            "Epoch 98, Average Loss: 4.433220154898507\n",
            "Epoch 99\n",
            "Step 0, Loss: 4.398507118225098\n",
            "Step 10, Loss: 4.346441268920898\n",
            "Step 20, Loss: 5.029390811920166\n",
            "Step 30, Loss: 3.7318789958953857\n",
            "Epoch 99, Average Loss: 4.4545757157461985\n",
            "Epoch 100\n",
            "Step 0, Loss: 4.265308856964111\n",
            "Step 10, Loss: 4.62464714050293\n",
            "Step 20, Loss: 4.453700065612793\n",
            "Step 30, Loss: 4.476571559906006\n",
            "Epoch 100, Average Loss: 4.3947149208613805\n",
            "Epoch 101\n",
            "Step 0, Loss: 4.354373455047607\n",
            "Step 10, Loss: 4.292250633239746\n",
            "Step 20, Loss: 4.50234317779541\n",
            "Step 30, Loss: 4.28065299987793\n",
            "Epoch 101, Average Loss: 4.508851058142525\n",
            "Epoch 102\n",
            "Step 0, Loss: 4.369578838348389\n",
            "Step 10, Loss: 4.341000080108643\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from torch.optim import AdamW\n",
        "from torch.cuda.amp import autocast, GradScaler\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "from transformers import MaskFormerForInstanceSegmentation, MaskFormerImageProcessor\n",
        "\n",
        "# Define the device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n",
        "\n",
        "# Load the MaskFormer model\n",
        "model = MaskFormerForInstanceSegmentation.from_pretrained(\n",
        "    \"facebook/maskformer-swin-tiny-ade\",\n",
        "    num_labels=6,  # Adjust based on dataset\n",
        "    ignore_mismatched_sizes=True\n",
        ").to(device)\n",
        "\n",
        "# Optimizer and Scheduler\n",
        "optimizer = AdamW(model.parameters(), lr=2e-5, weight_decay=0.01)\n",
        "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
        "\n",
        "# Mixed Precision Training\n",
        "scaler = GradScaler()\n",
        "\n",
        "# Training Loop\n",
        "model.train()\n",
        "for epoch in range(200):\n",
        "    print(f\"Epoch {epoch}\")\n",
        "    curr_epoch_loss = []\n",
        "\n",
        "    for idx, batch in enumerate(train_dataloader):\n",
        "      pixel_values = batch[\"pixel_values\"].to(device)\n",
        "      mask_labels = batch[\"labels\"].to(device)  # Shape: (batch_size, H, W)\n",
        "\n",
        "      optimizer.zero_grad()\n",
        "\n",
        "    # Mixed Precision Forward Pass\n",
        "      with autocast(dtype=torch.float16):\n",
        "        outputs = model(pixel_values=pixel_values)\n",
        "\n",
        "        # Use masks_queries_logits for predicted masks\n",
        "        mask_logits = outputs.masks_queries_logits  # Shape: (batch_size, num_queries, H, W)\n",
        "\n",
        "        # Interpolate logits to match mask_labels size\n",
        "        mask_logits = F.interpolate(\n",
        "            mask_logits, size=mask_labels.shape[-2:], mode=\"bilinear\", align_corners=False\n",
        "        )\n",
        "\n",
        "        # Ensure mask_logits has correct dimensions: (batch_size, num_classes, H, W)\n",
        "        # This might require mapping the queries to classes (depends on your setup)\n",
        "        mask_logits = mask_logits.permute(0, 2, 3, 1)  # Rearrange to (batch_size, H, W, num_queries)\n",
        "\n",
        "        # Compute Cross-Entropy Loss (logits should not have an argmax applied)\n",
        "        loss = F.cross_entropy(mask_logits, mask_labels)\n",
        "\n",
        "        # Backward Pass\n",
        "        scaler.scale(loss).backward()\n",
        "        scaler.step(optimizer)\n",
        "        scaler.update()\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        curr_epoch_loss.append(loss.item())\n",
        "        if idx % 10 == 0:\n",
        "            print(f\"Step {idx}, Loss: {loss.item()}\")\n",
        "\n",
        "    # Print epoch loss\n",
        "    print(f\"Epoch {epoch}, Average Loss: {sum(curr_epoch_loss) / len(curr_epoch_loss)}\")\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "# Evaluation Loop\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    eval_losses = []\n",
        "    metric.reset()  # Reset the metric before evaluation (optional for some metrics)\n",
        "\n",
        "    for batch in eval_dataloader:\n",
        "        pixel_values = batch[\"pixel_values\"].to(device)\n",
        "        mask_labels = batch[\"labels\"].to(device)\n",
        "\n",
        "        with autocast(dtype=torch.float16):  # Enable mixed precision\n",
        "            outputs = model(pixel_values=pixel_values)\n",
        "            mask_logits = outputs.masks_queries_logits  # MaskFormer raw logits\n",
        "\n",
        "            # Resize logits to match ground truth size\n",
        "            mask_logits = F.interpolate(\n",
        "                mask_logits, size=mask_labels.shape[-2:], mode=\"bilinear\", align_corners=False\n",
        "            )\n",
        "\n",
        "            # Compute loss\n",
        "            loss = F.cross_entropy(mask_logits, mask_labels)\n",
        "            eval_losses.append(loss.item())\n",
        "\n",
        "            # Convert logits to predicted class indices\n",
        "            predictions = mask_logits.argmax(dim=1).cpu().numpy()  # (batch_size, H, W)\n",
        "            references = mask_labels.cpu().numpy()  # Ground truth labels\n",
        "\n",
        "            # Add batch predictions and references to the metric\n",
        "            metric.add_batch(predictions=predictions, references=references)\n",
        "\n",
        "    # Compute the final metrics\n",
        "    results = metric.compute(num_labels=6, ignore_index=255)\n",
        "    mean_iou = results[\"mean_iou\"]\n",
        "    mean_accuracy = results[\"mean_accuracy\"]\n",
        "\n",
        "    # Log results\n",
        "    eval_loss_value = sum(eval_losses) / len(eval_losses)\n",
        "    eval_loss.append(eval_loss_value)\n",
        "    eval_iou.append(mean_iou)\n",
        "    eval_acc.append(mean_accuracy)\n",
        "\n",
        "    print(f\"Average Evaluation Loss: {eval_loss_value}\")\n",
        "    print(f\"Mean IoU: {mean_iou}\")\n",
        "    print(f\"Mean Accuracy: {mean_accuracy}\")\n",
        "\n",
        "    writer.add_scalar(\"Eval/Loss\", eval_loss_value, global_step=epoch)\n",
        "    writer.add_scalar(\"Eval/Mean_IoU\", mean_iou, global_step=epoch)\n",
        "    writer.add_scalar(\"Eval/Mean_Accuracy\", mean_accuracy, global_step=epoch)\n",
        "\n",
        "model.train()  # Return to training mode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0901ce21",
      "metadata": {
        "id": "0901ce21"
      },
      "outputs": [],
      "source": [
        "!kill -9 14330"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p8jOxDlI6oA2",
        "outputId": "00b933b7-6979-498e-8b6a-d486c71cf759"
      },
      "id": "p8jOxDlI6oA2",
      "execution_count": 174,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Dec 17 00:05:35 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   77C    P0              33W /  70W |  15101MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hn7Ps14x6oiz"
      },
      "id": "hn7Ps14x6oiz",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "venv"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.3"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "09ed323bc9b44bd7b4c3e9c5b2a805f9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_fa837d8dac3f4d33a75064aa9ed827d2",
              "IPY_MODEL_f06785a57e724bceb5a961ebf2892df1",
              "IPY_MODEL_5a7b4cd96a7c4b60b63a81a987b090ab"
            ],
            "layout": "IPY_MODEL_507b875bf6f8484393070bd44c135712"
          }
        },
        "fa837d8dac3f4d33a75064aa9ed827d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f4281f0ba2bc4b19a221c403099d1970",
            "placeholder": "​",
            "style": "IPY_MODEL_fafb2d6b93044cfea221e10d82f3e51e",
            "value": "Downloading builder script: 100%"
          }
        },
        "f06785a57e724bceb5a961ebf2892df1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bfee4dc4ed4c41a39484525b41849f04",
            "max": 12929,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_2613779b7fb3451ebf0e52b1c0f1f85a",
            "value": 12929
          }
        },
        "5a7b4cd96a7c4b60b63a81a987b090ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_1847b7877e2d43e4b9628ee979be64c0",
            "placeholder": "​",
            "style": "IPY_MODEL_ca896449c58445969e2aefb3a6e735b9",
            "value": " 12.9k/12.9k [00:00&lt;00:00, 725kB/s]"
          }
        },
        "507b875bf6f8484393070bd44c135712": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f4281f0ba2bc4b19a221c403099d1970": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fafb2d6b93044cfea221e10d82f3e51e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bfee4dc4ed4c41a39484525b41849f04": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2613779b7fb3451ebf0e52b1c0f1f85a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "1847b7877e2d43e4b9628ee979be64c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ca896449c58445969e2aefb3a6e735b9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}