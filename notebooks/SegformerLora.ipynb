{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0039360b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/Desktop/ML/venv/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/vlad/Desktop/ML/venv/lib/python3.12/site-packages/albumentations/__init__.py:24: UserWarning: A new version of Albumentations is available: 1.4.22 (you have 0.0.19). Upgrade using: pip install -U albumentations. To disable automatic update checks, set the environment variable NO_ALBUMENTATIONS_UPDATE to 1.\n",
      "  check_for_updates()\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as A\n",
    "from PIL import Image\n",
    "\n",
    "from datasets import load_metric\n",
    "from transformers import SegformerImageProcessor\n",
    "from transformers import SegformerForSemanticSegmentation\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from training.dataset import SemanticSegmentationDataset\n",
    "from peft import LoraConfig, get_peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "00299c33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_42682/1850387162.py:2: UserWarning: Argument 'ratio' is not valid and will be ignored.\n",
      "  A.RandomSizedCrop( (1000, 1000) , 1000, 1000,  ratio=(0.75, 1.33), p = 0.7),\n"
     ]
    }
   ],
   "source": [
    "augs = A.Compose([\n",
    "              A.RandomSizedCrop( (1000, 1000) , 1000, 1000,  ratio=(0.75, 1.33), p = 0.7),\n",
    "             A.RandomRain(p=0.05),\n",
    "             A.ShiftScaleRotate(p =0.4),\n",
    "             A.RGBShift(p =0.1),\n",
    "             A.Blur(p =0.2),\n",
    "             A.GaussNoise(p =0.2),\n",
    "             A.ElasticTransform(p =0.2),\n",
    "             A.MaskDropout((10,15), p =0.03),\n",
    "             A.MotionBlur(p=0.3), \n",
    "             A.RandomFog(p=0.3)\n",
    "        ], p=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a4a85906",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vlad/Desktop/ML/venv/lib/python3.12/site-packages/transformers/models/segformer/image_processing_segformer.py:103: FutureWarning: The `reduce_labels` parameter is deprecated and will be removed in a future version. Please use `do_reduce_labels` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "image_processor = SegformerImageProcessor(reduce_labels=True)\n",
    "img_dir = './data/imgs'\n",
    "masks_dir = './data/masks'\n",
    "\n",
    "train_ds, eval_ds = SemanticSegmentationDataset.get_train_and_eval_datasets(\n",
    "    processor, img_dir, masks_dir\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6b9c187b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_ds, batch_size=8, shuffle=True)\n",
    "eval_dataloader = DataLoader(eval_ds, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75477c00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f36b7159",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/mit-b0 and are newly initialized: ['decode_head.batch_norm.bias', 'decode_head.batch_norm.num_batches_tracked', 'decode_head.batch_norm.running_mean', 'decode_head.batch_norm.running_var', 'decode_head.batch_norm.weight', 'decode_head.classifier.bias', 'decode_head.classifier.weight', 'decode_head.linear_c.0.proj.bias', 'decode_head.linear_c.0.proj.weight', 'decode_head.linear_c.1.proj.bias', 'decode_head.linear_c.1.proj.weight', 'decode_head.linear_c.2.proj.bias', 'decode_head.linear_c.2.proj.weight', 'decode_head.linear_c.3.proj.bias', 'decode_head.linear_c.3.proj.weight', 'decode_head.linear_fuse.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "PeftModel(\n",
       "  (base_model): LoraModel(\n",
       "    (model): SegformerForSemanticSegmentation(\n",
       "      (segformer): SegformerModel(\n",
       "        (encoder): SegformerEncoder(\n",
       "          (patch_embeddings): ModuleList(\n",
       "            (0): SegformerOverlapPatchEmbeddings(\n",
       "              (proj): Conv2d(3, 32, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
       "              (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (1): SegformerOverlapPatchEmbeddings(\n",
       "              (proj): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "              (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (2): SegformerOverlapPatchEmbeddings(\n",
       "              (proj): Conv2d(64, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "              (layer_norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "            (3): SegformerOverlapPatchEmbeddings(\n",
       "              (proj): Conv2d(160, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "              (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            )\n",
       "          )\n",
       "          (block): ModuleList(\n",
       "            (0): ModuleList(\n",
       "              (0): SegformerLayer(\n",
       "                (layer_norm_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "                (attention): SegformerAttention(\n",
       "                  (self): SegformerEfficientSelfAttention(\n",
       "                    (query): lora.Linear(\n",
       "                      (base_layer): Linear(in_features=32, out_features=32, bias=True)\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Dropout(p=0.1, inplace=False)\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=32, out_features=32, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=32, out_features=32, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                    )\n",
       "                    (key): Linear(in_features=32, out_features=32, bias=True)\n",
       "                    (value): lora.Linear(\n",
       "                      (base_layer): Linear(in_features=32, out_features=32, bias=True)\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Dropout(p=0.1, inplace=False)\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=32, out_features=32, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=32, out_features=32, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                    )\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    (sr): Conv2d(32, 32, kernel_size=(8, 8), stride=(8, 8))\n",
       "                    (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "                  )\n",
       "                  (output): SegformerSelfOutput(\n",
       "                    (dense): Linear(in_features=32, out_features=32, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): Identity()\n",
       "                (layer_norm_2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): SegformerMixFFN(\n",
       "                  (dense1): Linear(in_features=32, out_features=128, bias=True)\n",
       "                  (dwconv): SegformerDWConv(\n",
       "                    (dwconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "                  )\n",
       "                  (intermediate_act_fn): GELUActivation()\n",
       "                  (dense2): Linear(in_features=128, out_features=32, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (1): SegformerLayer(\n",
       "                (layer_norm_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "                (attention): SegformerAttention(\n",
       "                  (self): SegformerEfficientSelfAttention(\n",
       "                    (query): lora.Linear(\n",
       "                      (base_layer): Linear(in_features=32, out_features=32, bias=True)\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Dropout(p=0.1, inplace=False)\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=32, out_features=32, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=32, out_features=32, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                    )\n",
       "                    (key): Linear(in_features=32, out_features=32, bias=True)\n",
       "                    (value): lora.Linear(\n",
       "                      (base_layer): Linear(in_features=32, out_features=32, bias=True)\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Dropout(p=0.1, inplace=False)\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=32, out_features=32, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=32, out_features=32, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                    )\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    (sr): Conv2d(32, 32, kernel_size=(8, 8), stride=(8, 8))\n",
       "                    (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "                  )\n",
       "                  (output): SegformerSelfOutput(\n",
       "                    (dense): Linear(in_features=32, out_features=32, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): SegformerDropPath(p=0.014285714365541935)\n",
       "                (layer_norm_2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): SegformerMixFFN(\n",
       "                  (dense1): Linear(in_features=32, out_features=128, bias=True)\n",
       "                  (dwconv): SegformerDWConv(\n",
       "                    (dwconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "                  )\n",
       "                  (intermediate_act_fn): GELUActivation()\n",
       "                  (dense2): Linear(in_features=128, out_features=32, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (1): ModuleList(\n",
       "              (0): SegformerLayer(\n",
       "                (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "                (attention): SegformerAttention(\n",
       "                  (self): SegformerEfficientSelfAttention(\n",
       "                    (query): lora.Linear(\n",
       "                      (base_layer): Linear(in_features=64, out_features=64, bias=True)\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Dropout(p=0.1, inplace=False)\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=64, out_features=32, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=32, out_features=64, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                    )\n",
       "                    (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "                    (value): lora.Linear(\n",
       "                      (base_layer): Linear(in_features=64, out_features=64, bias=True)\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Dropout(p=0.1, inplace=False)\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=64, out_features=32, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=32, out_features=64, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                    )\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    (sr): Conv2d(64, 64, kernel_size=(4, 4), stride=(4, 4))\n",
       "                    (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "                  )\n",
       "                  (output): SegformerSelfOutput(\n",
       "                    (dense): Linear(in_features=64, out_features=64, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): SegformerDropPath(p=0.02857142873108387)\n",
       "                (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): SegformerMixFFN(\n",
       "                  (dense1): Linear(in_features=64, out_features=256, bias=True)\n",
       "                  (dwconv): SegformerDWConv(\n",
       "                    (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "                  )\n",
       "                  (intermediate_act_fn): GELUActivation()\n",
       "                  (dense2): Linear(in_features=256, out_features=64, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (1): SegformerLayer(\n",
       "                (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "                (attention): SegformerAttention(\n",
       "                  (self): SegformerEfficientSelfAttention(\n",
       "                    (query): lora.Linear(\n",
       "                      (base_layer): Linear(in_features=64, out_features=64, bias=True)\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Dropout(p=0.1, inplace=False)\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=64, out_features=32, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=32, out_features=64, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                    )\n",
       "                    (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "                    (value): lora.Linear(\n",
       "                      (base_layer): Linear(in_features=64, out_features=64, bias=True)\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Dropout(p=0.1, inplace=False)\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=64, out_features=32, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=32, out_features=64, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                    )\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    (sr): Conv2d(64, 64, kernel_size=(4, 4), stride=(4, 4))\n",
       "                    (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "                  )\n",
       "                  (output): SegformerSelfOutput(\n",
       "                    (dense): Linear(in_features=64, out_features=64, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): SegformerDropPath(p=0.04285714402794838)\n",
       "                (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): SegformerMixFFN(\n",
       "                  (dense1): Linear(in_features=64, out_features=256, bias=True)\n",
       "                  (dwconv): SegformerDWConv(\n",
       "                    (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "                  )\n",
       "                  (intermediate_act_fn): GELUActivation()\n",
       "                  (dense2): Linear(in_features=256, out_features=64, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (2): ModuleList(\n",
       "              (0): SegformerLayer(\n",
       "                (layer_norm_1): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "                (attention): SegformerAttention(\n",
       "                  (self): SegformerEfficientSelfAttention(\n",
       "                    (query): lora.Linear(\n",
       "                      (base_layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Dropout(p=0.1, inplace=False)\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=160, out_features=32, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=32, out_features=160, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                    )\n",
       "                    (key): Linear(in_features=160, out_features=160, bias=True)\n",
       "                    (value): lora.Linear(\n",
       "                      (base_layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Dropout(p=0.1, inplace=False)\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=160, out_features=32, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=32, out_features=160, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                    )\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    (sr): Conv2d(160, 160, kernel_size=(2, 2), stride=(2, 2))\n",
       "                    (layer_norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "                  )\n",
       "                  (output): SegformerSelfOutput(\n",
       "                    (dense): Linear(in_features=160, out_features=160, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): SegformerDropPath(p=0.05714285746216774)\n",
       "                (layer_norm_2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): SegformerMixFFN(\n",
       "                  (dense1): Linear(in_features=160, out_features=640, bias=True)\n",
       "                  (dwconv): SegformerDWConv(\n",
       "                    (dwconv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)\n",
       "                  )\n",
       "                  (intermediate_act_fn): GELUActivation()\n",
       "                  (dense2): Linear(in_features=640, out_features=160, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (1): SegformerLayer(\n",
       "                (layer_norm_1): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "                (attention): SegformerAttention(\n",
       "                  (self): SegformerEfficientSelfAttention(\n",
       "                    (query): lora.Linear(\n",
       "                      (base_layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Dropout(p=0.1, inplace=False)\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=160, out_features=32, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=32, out_features=160, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                    )\n",
       "                    (key): Linear(in_features=160, out_features=160, bias=True)\n",
       "                    (value): lora.Linear(\n",
       "                      (base_layer): Linear(in_features=160, out_features=160, bias=True)\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Dropout(p=0.1, inplace=False)\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=160, out_features=32, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=32, out_features=160, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                    )\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                    (sr): Conv2d(160, 160, kernel_size=(2, 2), stride=(2, 2))\n",
       "                    (layer_norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "                  )\n",
       "                  (output): SegformerSelfOutput(\n",
       "                    (dense): Linear(in_features=160, out_features=160, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): SegformerDropPath(p=0.0714285746216774)\n",
       "                (layer_norm_2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): SegformerMixFFN(\n",
       "                  (dense1): Linear(in_features=160, out_features=640, bias=True)\n",
       "                  (dwconv): SegformerDWConv(\n",
       "                    (dwconv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)\n",
       "                  )\n",
       "                  (intermediate_act_fn): GELUActivation()\n",
       "                  (dense2): Linear(in_features=640, out_features=160, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "            (3): ModuleList(\n",
       "              (0): SegformerLayer(\n",
       "                (layer_norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                (attention): SegformerAttention(\n",
       "                  (self): SegformerEfficientSelfAttention(\n",
       "                    (query): lora.Linear(\n",
       "                      (base_layer): Linear(in_features=256, out_features=256, bias=True)\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Dropout(p=0.1, inplace=False)\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=256, out_features=32, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=32, out_features=256, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                    )\n",
       "                    (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "                    (value): lora.Linear(\n",
       "                      (base_layer): Linear(in_features=256, out_features=256, bias=True)\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Dropout(p=0.1, inplace=False)\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=256, out_features=32, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=32, out_features=256, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                    )\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (output): SegformerSelfOutput(\n",
       "                    (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): SegformerDropPath(p=0.08571428805589676)\n",
       "                (layer_norm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): SegformerMixFFN(\n",
       "                  (dense1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                  (dwconv): SegformerDWConv(\n",
       "                    (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                  )\n",
       "                  (intermediate_act_fn): GELUActivation()\n",
       "                  (dense2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "              (1): SegformerLayer(\n",
       "                (layer_norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                (attention): SegformerAttention(\n",
       "                  (self): SegformerEfficientSelfAttention(\n",
       "                    (query): lora.Linear(\n",
       "                      (base_layer): Linear(in_features=256, out_features=256, bias=True)\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Dropout(p=0.1, inplace=False)\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=256, out_features=32, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=32, out_features=256, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                    )\n",
       "                    (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "                    (value): lora.Linear(\n",
       "                      (base_layer): Linear(in_features=256, out_features=256, bias=True)\n",
       "                      (lora_dropout): ModuleDict(\n",
       "                        (default): Dropout(p=0.1, inplace=False)\n",
       "                      )\n",
       "                      (lora_A): ModuleDict(\n",
       "                        (default): Linear(in_features=256, out_features=32, bias=False)\n",
       "                      )\n",
       "                      (lora_B): ModuleDict(\n",
       "                        (default): Linear(in_features=32, out_features=256, bias=False)\n",
       "                      )\n",
       "                      (lora_embedding_A): ParameterDict()\n",
       "                      (lora_embedding_B): ParameterDict()\n",
       "                    )\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                  (output): SegformerSelfOutput(\n",
       "                    (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "                    (dropout): Dropout(p=0.0, inplace=False)\n",
       "                  )\n",
       "                )\n",
       "                (drop_path): SegformerDropPath(p=0.10000000149011612)\n",
       "                (layer_norm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "                (mlp): SegformerMixFFN(\n",
       "                  (dense1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "                  (dwconv): SegformerDWConv(\n",
       "                    (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "                  )\n",
       "                  (intermediate_act_fn): GELUActivation()\n",
       "                  (dense2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "                  (dropout): Dropout(p=0.0, inplace=False)\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "          (layer_norm): ModuleList(\n",
       "            (0): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "            (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "            (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (decode_head): ModulesToSaveWrapper(\n",
       "        (original_module): SegformerDecodeHead(\n",
       "          (linear_c): ModuleList(\n",
       "            (0): SegformerMLP(\n",
       "              (proj): Linear(in_features=32, out_features=256, bias=True)\n",
       "            )\n",
       "            (1): SegformerMLP(\n",
       "              (proj): Linear(in_features=64, out_features=256, bias=True)\n",
       "            )\n",
       "            (2): SegformerMLP(\n",
       "              (proj): Linear(in_features=160, out_features=256, bias=True)\n",
       "            )\n",
       "            (3): SegformerMLP(\n",
       "              (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            )\n",
       "          )\n",
       "          (linear_fuse): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "          (batch_norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (activation): ReLU()\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "          (classifier): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "        )\n",
       "        (modules_to_save): ModuleDict(\n",
       "          (default): SegformerDecodeHead(\n",
       "            (linear_c): ModuleList(\n",
       "              (0): SegformerMLP(\n",
       "                (proj): Linear(in_features=32, out_features=256, bias=True)\n",
       "              )\n",
       "              (1): SegformerMLP(\n",
       "                (proj): Linear(in_features=64, out_features=256, bias=True)\n",
       "              )\n",
       "              (2): SegformerMLP(\n",
       "                (proj): Linear(in_features=160, out_features=256, bias=True)\n",
       "              )\n",
       "              (3): SegformerMLP(\n",
       "                (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (linear_fuse): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (batch_norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "            (activation): ReLU()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "            (classifier): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/mit-b0\",\n",
    "                                                         num_labels=6,\n",
    "                                                       #  id2label=id2label,\n",
    "                                                       #  label2id=label2id,\n",
    ")\n",
    "config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=32,\n",
    "    target_modules=[\"query\", \"value\"],\n",
    "    lora_dropout=0.1,\n",
    "    bias=\"lora_only\",\n",
    "    modules_to_save=[\"decode_head\"],\n",
    ")\n",
    "\n",
    "model = get_peft_model(model, config)\n",
    "\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0deaab48",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_path = './lora_segformer'\n",
    "writer = SummaryWriter(log_path)\n",
    "metric = load_metric(\"mean_iou\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddb71b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff298841",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                   | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n",
      "Mean_iou: 0.1528387801737399\n",
      "Loss: 1.5240730709499783\n",
      "Mean accuracy: 0.27104480108992396\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|â–                                      | 1/200 [03:23<11:14:48, 203.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.0005)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "train_loss_iter = []\n",
    "train_loss_epoch = []\n",
    "eval_iou = []\n",
    "eval_acc = []\n",
    "eval_loss = []\n",
    "model.train()\n",
    "best_iou = 0 \n",
    "best_acc = 0\n",
    "for epoch in tqdm(range(200)):  # loop over the dataset multiple times\n",
    "    print(\"Epoch:\", epoch)\n",
    "    curr_epoch_loss = []\n",
    "    curr_epoch_eval_loss = []\n",
    "    for idx, batch in enumerate(train_dataloader):\n",
    "        \n",
    "        pixel_values = batch[\"pixel_values\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(pixel_values=pixel_values, labels=labels)\n",
    "        loss, logits = outputs.loss, outputs.logits\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #print()\n",
    "        train_loss_iter.append(loss.item())\n",
    "        curr_epoch_loss.append(loss.item())\n",
    "        writer.add_scalar(\"Train/loss_step\", train_loss_iter[-1], idx + epoch * len(train_dataloader))\n",
    "        writer.add_scalar(\"Train/epoch\", epoch + 1, idx + epoch * len(train_dataloader))\n",
    "    train_loss_epoch.append(sum(curr_epoch_loss) / len(curr_epoch_loss))   \n",
    "    writer.add_scalar(\"Train/loss_epoch\", train_loss_epoch[-1], epoch + 1)\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for batch in eval_dataloader:\n",
    "            pixel_values = batch[\"pixel_values\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            outputs = model(pixel_values=pixel_values, labels=labels)\n",
    "            loss, logits = outputs.loss, outputs.logits\n",
    "            curr_epoch_eval_loss.append(outputs.loss.item())\n",
    "            upsampled_logits = torch.nn.functional.interpolate(logits, size=labels.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "            predicted = upsampled_logits.argmax(dim=1)\n",
    "            metric.add_batch(predictions=predicted.detach().cpu().numpy(), references=labels.detach().cpu().numpy())\n",
    "            \n",
    "        metrics = metric.compute(num_labels=6, \n",
    "                                       ignore_index=255,\n",
    "                                       reduce_labels=False, # we've already reduced the labels before)\n",
    "            )\n",
    "        eval_iou.append( metrics[\"mean_iou\"])\n",
    "        eval_acc.append(metrics[\"mean_accuracy\"])\n",
    "        eval_loss.append(sum(curr_epoch_eval_loss) / len(eval_dataloader))\n",
    "        \n",
    "        writer.add_scalar(\"Eval/loss\",eval_loss[-1], epoch + 1)\n",
    "        writer.add_scalar(\"Eval/Accuracy\", metrics[\"mean_accuracy\"], epoch + 1)\n",
    "        writer.add_scalar(\"Eval/IoU\", metrics[\"mean_iou\"], epoch + 1)\n",
    "        \n",
    "        print(\"Mean_iou:\", metrics[\"mean_iou\"])\n",
    "        print(\"Loss:\", train_loss_epoch[-1])\n",
    "        print(\"Mean accuracy:\", metrics[\"mean_accuracy\"])\n",
    "        \n",
    "        if metrics[\"mean_iou\"] > best_iou: \n",
    "            torch.save({\"model\" : model.state_dict() }, 'bect_iou_segformer_lora.ckpt') \n",
    "            best_iou = metrics[\"mean_iou\"]\n",
    "        if metrics[\"mean_accuracy\"] > best_acc: \n",
    "            torch.save({\"model\" : model.state_dict() }, 'bect_acc_segformer_lora.ckpt') \n",
    "            best_acc = metrics[\"mean_accuracy\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf80354",
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da13ea87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/bash: line 1: kill: (14330) - No such process\r\n"
     ]
    }
   ],
   "source": [
    "!kill -9 14330"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4cd2d3d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
