{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f4de41c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b1bbc846",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch \n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "from datasets import load_metric\n",
    "from transformers import SegformerImageProcessor\n",
    "from transformers import SegformerForSemanticSegmentation\n",
    "\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "34dbdce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SemanticSegmentationDataset(Dataset):\n",
    "    \"\"\"Image (semantic) segmentation dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, image_processor, train, img_dir = './data/imgs', masks_dir = './data/masks'):\n",
    "        \n",
    "\n",
    "        self.img_pathes = [ f'{img_dir}/{item}' for item in sorted(os.listdir(img_dir)) ]\n",
    "        self.img_pathes = [item for item in self.img_pathes if item[-3:] == 'jpg']\n",
    "        self.mask_pathes = [ f'{masks_dir}/{item}' for item in sorted(os.listdir(masks_dir)) ]\n",
    "        # Евалюсь на последних 20 чтоб не ебаться с шаффлами\n",
    "        if train == False: \n",
    "            self.img_pathes = self.img_pathes[:20]\n",
    "            self.mask_pathes = self.mask_pathes[:20]\n",
    "        \n",
    "        self.image_processor = image_processor\n",
    "\n",
    "        assert len(self.img_pathes) == len(self.mask_pathes), \"There must be as many images as there are segmentation maps\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_pathes)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        mask = np.load(self.mask_pathes[idx])\n",
    "        image = np.array( Image.open(self.img_pathes[idx])) \n",
    "\n",
    "        encoded_inputs = self.image_processor(image, mask, return_tensors=\"pt\")\n",
    "\n",
    "        for k,v in encoded_inputs.items():\n",
    "            encoded_inputs[k].squeeze_() # remove batch dimension\n",
    "\n",
    "        return encoded_inputs\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24027c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_processor = SegformerImageProcessor(reduce_labels=False)\n",
    "train_ds = SemanticSegmentationDataset(image_processor, True)\n",
    "eval_ds = SemanticSegmentationDataset(image_processor, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccea9e94",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_ds, batch_size=8, shuffle=True)\n",
    "eval_dataloader = DataLoader(eval_ds, batch_size=8, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "663c1f0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of SegformerForSemanticSegmentation were not initialized from the model checkpoint at nvidia/mit-b0 and are newly initialized: ['decode_head.batch_norm.bias', 'decode_head.batch_norm.num_batches_tracked', 'decode_head.batch_norm.running_mean', 'decode_head.batch_norm.running_var', 'decode_head.batch_norm.weight', 'decode_head.classifier.bias', 'decode_head.classifier.weight', 'decode_head.linear_c.0.proj.bias', 'decode_head.linear_c.0.proj.weight', 'decode_head.linear_c.1.proj.bias', 'decode_head.linear_c.1.proj.weight', 'decode_head.linear_c.2.proj.bias', 'decode_head.linear_c.2.proj.weight', 'decode_head.linear_c.3.proj.bias', 'decode_head.linear_c.3.proj.weight', 'decode_head.linear_fuse.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SegformerForSemanticSegmentation(\n",
       "  (segformer): SegformerModel(\n",
       "    (encoder): SegformerEncoder(\n",
       "      (patch_embeddings): ModuleList(\n",
       "        (0): SegformerOverlapPatchEmbeddings(\n",
       "          (proj): Conv2d(3, 32, kernel_size=(7, 7), stride=(4, 4), padding=(3, 3))\n",
       "          (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (1): SegformerOverlapPatchEmbeddings(\n",
       "          (proj): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (2): SegformerOverlapPatchEmbeddings(\n",
       "          (proj): Conv2d(64, 160, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (layer_norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "        (3): SegformerOverlapPatchEmbeddings(\n",
       "          (proj): Conv2d(160, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
       "          (layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (block): ModuleList(\n",
       "        (0): ModuleList(\n",
       "          (0): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=32, out_features=32, bias=True)\n",
       "                (key): Linear(in_features=32, out_features=32, bias=True)\n",
       "                (value): Linear(in_features=32, out_features=32, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(32, 32, kernel_size=(8, 8), stride=(8, 8))\n",
       "                (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=32, out_features=32, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): Identity()\n",
       "            (layer_norm_2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=32, out_features=128, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=128, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=32, out_features=32, bias=True)\n",
       "                (key): Linear(in_features=32, out_features=32, bias=True)\n",
       "                (value): Linear(in_features=32, out_features=32, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(32, 32, kernel_size=(8, 8), stride=(8, 8))\n",
       "                (layer_norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=32, out_features=32, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.014285714365541935)\n",
       "            (layer_norm_2): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=32, out_features=128, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=128)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=128, out_features=32, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (1): ModuleList(\n",
       "          (0): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(64, 64, kernel_size=(4, 4), stride=(4, 4))\n",
       "                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.02857142873108387)\n",
       "            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=64, out_features=256, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=256, out_features=64, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (key): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (value): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(64, 64, kernel_size=(4, 4), stride=(4, 4))\n",
       "                (layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=64, out_features=64, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.04285714402794838)\n",
       "            (layer_norm_2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=64, out_features=256, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=256)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=256, out_features=64, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (2): ModuleList(\n",
       "          (0): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=160, out_features=160, bias=True)\n",
       "                (key): Linear(in_features=160, out_features=160, bias=True)\n",
       "                (value): Linear(in_features=160, out_features=160, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(160, 160, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=160, out_features=160, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.05714285746216774)\n",
       "            (layer_norm_2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=160, out_features=160, bias=True)\n",
       "                (key): Linear(in_features=160, out_features=160, bias=True)\n",
       "                (value): Linear(in_features=160, out_features=160, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "                (sr): Conv2d(160, 160, kernel_size=(2, 2), stride=(2, 2))\n",
       "                (layer_norm): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=160, out_features=160, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.0714285746216774)\n",
       "            (layer_norm_2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=160, out_features=640, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(640, 640, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=640)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=640, out_features=160, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (3): ModuleList(\n",
       "          (0): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.08571428805589676)\n",
       "            (layer_norm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): SegformerLayer(\n",
       "            (layer_norm_1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (attention): SegformerAttention(\n",
       "              (self): SegformerEfficientSelfAttention(\n",
       "                (query): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (key): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (value): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "              (output): SegformerSelfOutput(\n",
       "                (dense): Linear(in_features=256, out_features=256, bias=True)\n",
       "                (dropout): Dropout(p=0.0, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (drop_path): SegformerDropPath(p=0.10000000149011612)\n",
       "            (layer_norm_2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "            (mlp): SegformerMixFFN(\n",
       "              (dense1): Linear(in_features=256, out_features=1024, bias=True)\n",
       "              (dwconv): SegformerDWConv(\n",
       "                (dwconv): Conv2d(1024, 1024, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=1024)\n",
       "              )\n",
       "              (intermediate_act_fn): GELUActivation()\n",
       "              (dense2): Linear(in_features=1024, out_features=256, bias=True)\n",
       "              (dropout): Dropout(p=0.0, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (layer_norm): ModuleList(\n",
       "        (0): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
       "        (1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (2): LayerNorm((160,), eps=1e-05, elementwise_affine=True)\n",
       "        (3): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (decode_head): SegformerDecodeHead(\n",
       "    (linear_c): ModuleList(\n",
       "      (0): SegformerMLP(\n",
       "        (proj): Linear(in_features=32, out_features=256, bias=True)\n",
       "      )\n",
       "      (1): SegformerMLP(\n",
       "        (proj): Linear(in_features=64, out_features=256, bias=True)\n",
       "      )\n",
       "      (2): SegformerMLP(\n",
       "        (proj): Linear(in_features=160, out_features=256, bias=True)\n",
       "      )\n",
       "      (3): SegformerMLP(\n",
       "        (proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "    )\n",
       "    (linear_fuse): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (batch_norm): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (activation): ReLU()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (classifier): Conv2d(256, 6, kernel_size=(1, 1), stride=(1, 1))\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = SegformerForSemanticSegmentation.from_pretrained(\"nvidia/mit-b0\",\n",
    "                                                         num_labels=6,\n",
    "                                                       #  id2label=id2label,\n",
    "                                                       #  label2id=label2id,\n",
    ")\n",
    "model.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78250893",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_25584/3089766150.py:3: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library 🤗 Evaluate: https://huggingface.co/docs/evaluate\n",
      "  metric = load_metric(\"mean_iou\")\n"
     ]
    }
   ],
   "source": [
    "log_path = './logs'\n",
    "writer = SummaryWriter(log_path)\n",
    "metric = load_metric(\"mean_iou\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5017b102",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                   | 0/200 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▏                                       | 1/200 [02:09<7:08:12, 129.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_iou: 0.2652821412123574\n",
      "Loss: 1.636090874671936\n",
      "Mean accuracy: 0.35721163772084336\n",
      "Epoch: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  1%|▍                                       | 2/200 [04:08<6:46:45, 123.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean_iou: 0.2684602946840831\n",
      "Loss: 1.3528793183240024\n",
      "Mean accuracy: 0.34861102911303227\n",
      "Epoch: 2\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from tqdm import tqdm\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=0.00006)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "\n",
    "train_loss_iter = []\n",
    "train_loss_epoch = []\n",
    "eval_iou = []\n",
    "eval_acc = []\n",
    "eval_loss = []\n",
    "model.train()\n",
    "\n",
    "for epoch in tqdm(range(200)):  # loop over the dataset multiple times\n",
    "    print(\"Epoch:\", epoch)\n",
    "    curr_epoch_loss = []\n",
    "    curr_epoch_eval_loss = []\n",
    "    for idx, batch in enumerate(train_dataloader):\n",
    "        \n",
    "        pixel_values = batch[\"pixel_values\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(pixel_values=pixel_values, labels=labels)\n",
    "        loss, logits = outputs.loss, outputs.logits\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #print()\n",
    "        train_loss_iter.append(loss.item())\n",
    "        curr_epoch_loss.append(loss.item())\n",
    "        writer.add_scalar(\"Train/loss_step\", train_loss_iter[-1], idx + epoch * len(train_dataloader))\n",
    "        writer.add_scalar(\"Train/epoch\", epoch + 1, idx + epoch * len(train_dataloader))\n",
    "    train_loss_epoch.append(sum(curr_epoch_loss) / len(curr_epoch_loss))   \n",
    "    writer.add_scalar(\"Train/loss_epoch\", train_loss_epoch[-1], epoch + 1)\n",
    "    with torch.no_grad():\n",
    "        \n",
    "        for batch in eval_dataloader:\n",
    "            pixel_values = batch[\"pixel_values\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "            outputs = model(pixel_values=pixel_values, labels=labels)\n",
    "            loss, logits = outputs.loss, outputs.logits\n",
    "            curr_epoch_eval_loss.append(outputs.loss.item())\n",
    "            upsampled_logits = torch.nn.functional.interpolate(logits, size=labels.shape[-2:], mode=\"bilinear\", align_corners=False)\n",
    "            predicted = upsampled_logits.argmax(dim=1)\n",
    "            metric.add_batch(predictions=predicted.detach().cpu().numpy(), references=labels.detach().cpu().numpy())\n",
    "            \n",
    "        metrics = metric.compute(num_labels=6, \n",
    "                                       ignore_index=255,\n",
    "                                       reduce_labels=False, # we've already reduced the labels before)\n",
    "            )\n",
    "        eval_iou.append( metrics[\"mean_iou\"])\n",
    "        eval_acc.append(metrics[\"mean_accuracy\"])\n",
    "        eval_loss.append(sum(curr_epoch_eval_loss) / len(eval_dataloader))\n",
    "        \n",
    "        writer.add_scalar(\"Eval/loss\",eval_loss[-1], epoch + 1)\n",
    "        writer.add_scalar(\"Eval/Accuracy\", metrics[\"mean_accuracy\"], epoch + 1)\n",
    "        writer.add_scalar(\"Eval/IoU\", metrics[\"mean_iou\"], epoch + 1)\n",
    "        \n",
    "        print(\"Mean_iou:\", metrics[\"mean_iou\"])\n",
    "        print(\"Loss:\", train_loss_epoch[-1])\n",
    "        print(\"Mean accuracy:\", metrics[\"mean_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cad908cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Dec 16 23:42:17 2024       \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 535.183.01             Driver Version: 535.183.01   CUDA Version: 12.2     |\n",
      "|-----------------------------------------+----------------------+----------------------+\n",
      "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                                         |                      |               MIG M. |\n",
      "|=========================================+======================+======================|\n",
      "|   0  NVIDIA GeForce GTX 1650 Ti     Off | 00000000:01:00.0  On |                  N/A |\n",
      "| N/A   67C    P8               4W /  50W |   3896MiB /  4096MiB |      2%      Default |\n",
      "|                                         |                      |                  N/A |\n",
      "+-----------------------------------------+----------------------+----------------------+\n",
      "                                                                                         \n",
      "+---------------------------------------------------------------------------------------+\n",
      "| Processes:                                                                            |\n",
      "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
      "|        ID   ID                                                             Usage      |\n",
      "|=======================================================================================|\n",
      "|    0   N/A  N/A      8537      G   /usr/bin/gnome-shell                         65MiB |\n",
      "|    0   N/A  N/A     14330      C   /home/vlad/Desktop/ML/venv/bin/python3     3636MiB |\n",
      "|    0   N/A  N/A     25584      C   /home/vlad/Desktop/ML/venv/bin/python3      190MiB |\n",
      "+---------------------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0901ce21",
   "metadata": {},
   "outputs": [],
   "source": [
    "!kill -9 14330"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
